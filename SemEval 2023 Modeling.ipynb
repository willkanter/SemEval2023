{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b19933",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Read-in-data-and-Prep-work\" data-toc-modified-id=\"Read-in-data-and-Prep-work-1\">Read in data and Prep work</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-1.1\">Data</a></span></li><li><span><a href=\"#Prep-the-tokenizer-class\" data-toc-modified-id=\"Prep-the-tokenizer-class-1.2\">Prep the tokenizer class</a></span></li><li><span><a href=\"#Prep-the-&quot;Stance&quot;-label\" data-toc-modified-id=\"Prep-the-&quot;Stance&quot;-label-1.3\">Prep the \"Stance\" label</a></span></li><li><span><a href=\"#Prep-premises,-conslusions,-and-stance-labels\" data-toc-modified-id=\"Prep-premises,-conslusions,-and-stance-labels-1.4\">Prep premises, conslusions, and stance labels</a></span></li><li><span><a href=\"#One-hot-encode-the-stance-label-for-Neural-net-architecture\" data-toc-modified-id=\"One-hot-encode-the-stance-label-for-Neural-net-architecture-1.5\">One hot encode the stance label for Neural net architecture</a></span></li><li><span><a href=\"#Batch-the-Train,-Validation,-and-Test-sets\" data-toc-modified-id=\"Batch-the-Train,-Validation,-and-Test-sets-1.6\">Batch the Train, Validation, and Test sets</a></span><ul class=\"toc-item\"><li><span><a href=\"#Selecting-which-labels-to-predict\" data-toc-modified-id=\"Selecting-which-labels-to-predict-1.6.1\">Selecting which labels to predict</a></span></li></ul></li></ul></li><li><span><a href=\"#Naive-Model-1\" data-toc-modified-id=\"Naive-Model-1-2\">Naive Model 1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-3-labels\" data-toc-modified-id=\"Using-3-labels-2.1\">Using 3 labels</a></span><ul class=\"toc-item\"><li><span><a href=\"#Final-F1-score\" data-toc-modified-id=\"Final-F1-score-2.1.1\">Final F1 score</a></span></li><li><span><a href=\"#Predicting-on-Test-Set\" data-toc-modified-id=\"Predicting-on-Test-Set-2.1.2\">Predicting on Test Set</a></span></li></ul></li><li><span><a href=\"#Using-full-labels\" data-toc-modified-id=\"Using-full-labels-2.2\">Using full labels</a></span><ul class=\"toc-item\"><li><span><a href=\"#Adjust-the-activation-layer\" data-toc-modified-id=\"Adjust-the-activation-layer-2.2.1\">Adjust the activation layer</a></span></li></ul></li></ul></li><li><span><a href=\"#Dual-Model-Approach\" data-toc-modified-id=\"Dual-Model-Approach-3\">Dual Model Approach</a></span><ul class=\"toc-item\"><li><span><a href=\"#Rough-sketch-of-how-the-ideal-system-would-work\" data-toc-modified-id=\"Rough-sketch-of-how-the-ideal-system-would-work-3.1\">Rough sketch of how the ideal system would work</a></span></li><li><span><a href=\"#Test-set-on-models\" data-toc-modified-id=\"Test-set-on-models-3.2\">Test set on models</a></span></li></ul></li><li><span><a href=\"#Smart-Model-Approach\" data-toc-modified-id=\"Smart-Model-Approach-4\">Smart Model Approach</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "824bf8c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:54:35.223722Z",
     "start_time": "2022-12-12T22:54:35.214523Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List, Dict\n",
    "from transformers import BertModel\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertForPreTraining\n",
    "from transformers import BertForSequenceClassification\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d116b",
   "metadata": {},
   "source": [
    "# Read in data and Prep work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9daa13",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93356f7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T18:52:25.604914Z",
     "start_time": "2022-12-12T18:52:25.561030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in favor of     2880\n",
      "against         2495\n",
      "in favour of      18\n",
      "Name: Stance, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Read in the original data\n",
    "training_arguments = pd.read_csv('./data/arguments-training.tsv',delimiter='\\t')\n",
    "validation_arguments = pd.read_csv('./data/arguments-validation.tsv',delimiter='\\t')\n",
    "test_arguments = pd.read_csv('./data/arguments-test.tsv',delimiter='\\t')\n",
    "\n",
    "# Americanize the UK \"favour\" (18 'in favour of' vs 2880 'in favor of')\n",
    "print(training_arguments['Stance'].value_counts())\n",
    "training_arguments.loc[training_arguments['Stance'] == \"in favour of\", 'Stance'] = \"in favor of\"\n",
    "validation_arguments.loc[validation_arguments['Stance'] == \"in favour of\", 'Stance'] = \"in favor of\"\n",
    "test_arguments.loc[test_arguments['Stance'] == \"in favour of\", 'Stance'] = \"in favor of\"\n",
    "\n",
    "training_semlabels = pd.read_csv('./data/labels-training.tsv',delimiter='\\t')\n",
    "validation_semlabels = pd.read_csv('./data/labels-validation.tsv',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10e20733",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T18:52:25.872901Z",
     "start_time": "2022-12-12T18:52:25.850319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Self-direction: thought</th>\n",
       "      <th>Self-direction: action</th>\n",
       "      <th>Stimulation</th>\n",
       "      <th>Hedonism</th>\n",
       "      <th>Achievement</th>\n",
       "      <th>Power: dominance</th>\n",
       "      <th>Power: resources</th>\n",
       "      <th>Face</th>\n",
       "      <th>Security: personal</th>\n",
       "      <th>...</th>\n",
       "      <th>Tradition</th>\n",
       "      <th>Conformity: rules</th>\n",
       "      <th>Conformity: interpersonal</th>\n",
       "      <th>Humility</th>\n",
       "      <th>Benevolence: caring</th>\n",
       "      <th>Benevolence: dependability</th>\n",
       "      <th>Universalism: concern</th>\n",
       "      <th>Universalism: nature</th>\n",
       "      <th>Universalism: tolerance</th>\n",
       "      <th>Universalism: objectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>E08016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5389</th>\n",
       "      <td>E08017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>E08018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>E08019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5392</th>\n",
       "      <td>E08020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5393 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Argument ID  Self-direction: thought  Self-direction: action  \\\n",
       "0         A01002                        0                       0   \n",
       "1         A01005                        0                       0   \n",
       "2         A01006                        0                       0   \n",
       "3         A01007                        0                       0   \n",
       "4         A01008                        0                       0   \n",
       "...          ...                      ...                     ...   \n",
       "5388      E08016                        0                       0   \n",
       "5389      E08017                        0                       0   \n",
       "5390      E08018                        0                       0   \n",
       "5391      E08019                        0                       0   \n",
       "5392      E08020                        0                       1   \n",
       "\n",
       "      Stimulation  Hedonism  Achievement  Power: dominance  Power: resources  \\\n",
       "0               0         0            0                 0                 0   \n",
       "1               0         0            0                 0                 0   \n",
       "2               0         0            0                 1                 0   \n",
       "3               0         0            0                 0                 0   \n",
       "4               0         0            0                 0                 0   \n",
       "...           ...       ...          ...               ...               ...   \n",
       "5388            0         0            1                 1                 0   \n",
       "5389            0         0            0                 0                 0   \n",
       "5390            0         0            0                 0                 0   \n",
       "5391            0         0            0                 0                 0   \n",
       "5392            0         0            0                 1                 0   \n",
       "\n",
       "      Face  Security: personal  ...  Tradition  Conformity: rules  \\\n",
       "0        0                   0  ...          0                  0   \n",
       "1        0                   1  ...          0                  0   \n",
       "2        0                   0  ...          0                  0   \n",
       "3        0                   0  ...          0                  1   \n",
       "4        0                   1  ...          0                  0   \n",
       "...    ...                 ...  ...        ...                ...   \n",
       "5388     0                   0  ...          0                  0   \n",
       "5389     0                   1  ...          0                  1   \n",
       "5390     0                   0  ...          0                  0   \n",
       "5391     0                   1  ...          0                  1   \n",
       "5392     0                   0  ...          0                  0   \n",
       "\n",
       "      Conformity: interpersonal  Humility  Benevolence: caring  \\\n",
       "0                             0         0                    0   \n",
       "1                             0         0                    0   \n",
       "2                             0         0                    0   \n",
       "3                             0         0                    0   \n",
       "4                             0         0                    1   \n",
       "...                         ...       ...                  ...   \n",
       "5388                          0         0                    0   \n",
       "5389                          0         0                    0   \n",
       "5390                          0         0                    0   \n",
       "5391                          0         0                    0   \n",
       "5392                          0         0                    0   \n",
       "\n",
       "      Benevolence: dependability  Universalism: concern  Universalism: nature  \\\n",
       "0                              0                      0                     0   \n",
       "1                              0                      0                     0   \n",
       "2                              0                      0                     0   \n",
       "3                              0                      1                     0   \n",
       "4                              0                      1                     0   \n",
       "...                          ...                    ...                   ...   \n",
       "5388                           1                      0                     0   \n",
       "5389                           1                      1                     0   \n",
       "5390                           1                      0                     1   \n",
       "5391                           1                      1                     0   \n",
       "5392                           1                      0                     0   \n",
       "\n",
       "      Universalism: tolerance  Universalism: objectivity  \n",
       "0                           0                          0  \n",
       "1                           0                          0  \n",
       "2                           0                          0  \n",
       "3                           0                          0  \n",
       "4                           0                          0  \n",
       "...                       ...                        ...  \n",
       "5388                        0                          0  \n",
       "5389                        0                          1  \n",
       "5390                        0                          0  \n",
       "5391                        0                          1  \n",
       "5392                        0                          0  \n",
       "\n",
       "[5393 rows x 21 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_semlabels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7058db37",
   "metadata": {},
   "source": [
    "## Prep the tokenizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1831d680",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T18:52:26.358271Z",
     "start_time": "2022-12-12T18:52:26.350047Z"
    }
   },
   "outputs": [],
   "source": [
    "class BatchTokenizer:\n",
    "    \"\"\"Tokenizes and pads a batch of input sentences.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the tokenizer\n",
    "\n",
    "        Args:\n",
    "            pad_symbol (Optional[str], optional): The symbol for a pad. Defaults to \"<P>\".\n",
    "        \"\"\"\n",
    "        self.hf_tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-small\")\n",
    "    \n",
    "    def get_sep_token(self,):\n",
    "        return self.hf_tokenizer.sep_token\n",
    "    \n",
    "    def __call__(self, prem_batch: List[str], hyp_batch: List[str]) -> List[List[str]]:\n",
    "        \"\"\"Uses the huggingface tokenizer to tokenize and pad a batch.\n",
    "\n",
    "        We return a dictionary of tensors per the huggingface model specification.\n",
    "\n",
    "        Args:\n",
    "            batch (List[str]): A List of sentence strings\n",
    "\n",
    "        Returns:\n",
    "            Dict: The dictionary of token specifications provided by HuggingFace\n",
    "        \"\"\"\n",
    "        # The HF tokenizer will PAD for us, and additionally combine \n",
    "        # The two sentences deimited by the [SEP] token.\n",
    "        enc = self.hf_tokenizer(\n",
    "            prem_batch,\n",
    "            hyp_batch,\n",
    "            padding=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f07f98fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T18:52:26.742683Z",
     "start_time": "2022-12-12T18:52:26.728179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['We should end affirmative action',\n",
       "        'affirmative action helps with employment equity.'],\n",
       "       ['We should end affirmative action',\n",
       "        'affirmative action can be considered discriminatory against poor whites'],\n",
       "       ['We should ban naturopathy',\n",
       "        'naturopathy is very dangerous for the most vulnerable people, like children and cancer patients. people use ineffective treatments and forgo proven cures, such as antibiotics or chemo, often resulting in death.'],\n",
       "       ...,\n",
       "       ['We should consider Russian interests in the EU policy.',\n",
       "        'It is neither in the interests of the EU nor Russia to split a long common history. The dialogue must never stop,  With respect and trade, interpersonal exchange, and further expansion of what almost ended in 2014. Here I am thinking of space exploration, and joint development of vehicles, aircraft, etc. Our time horizon must be long-term - back to where it once was and beyond - based on how the world changes. The economy of scale is completely dominant today. '],\n",
       "       ['We should adopt an extension of the application of qualified majority voting arrangements',\n",
       "        'Foreign Policy at the EU level should be based on an absolute majority, not unanimity.'],\n",
       "       ['We should abolish covid digital pass',\n",
       "        'You owe the fact that you can drink your coffee in public to the people who got vaccinated and thus made the virus a little more manageable.']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arguments.loc[:,[\"Conclusion\", \"Premise\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c191c9",
   "metadata": {},
   "source": [
    "## Prep the \"Stance\" label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "dfb18a35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:34:47.498620Z",
     "start_time": "2022-12-12T21:34:47.471442Z"
    }
   },
   "outputs": [],
   "source": [
    "training_arguments['label'] = (training_arguments['Stance'] == 'against').astype(int)\n",
    "validation_arguments['label'] = (validation_arguments['Stance'] == 'against').astype(int)\n",
    "test_arguments['label'] = (test_arguments['Stance'] == 'against').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f85faca5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:34:47.936194Z",
     "start_time": "2022-12-12T21:34:47.913976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>We should ban human cloning</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>we should ban human cloning as it will only ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>We should ban fast food</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>fast food should be banned because it is reall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>We should end the use of economic sanctions</td>\n",
       "      <td>against</td>\n",
       "      <td>sometimes economic sanctions are the only thin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>We should abolish capital punishment</td>\n",
       "      <td>against</td>\n",
       "      <td>capital punishment is sometimes the only optio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>We should ban factory farming</td>\n",
       "      <td>against</td>\n",
       "      <td>factory farming allows for the production of c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>E08016</td>\n",
       "      <td>The EU should integrate the armed forces of it...</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>On the one hand, we have Russia killing countl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5389</th>\n",
       "      <td>E08017</td>\n",
       "      <td>Food whose production has been subsidized with...</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>The subsidies were originally intended to ensu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>E08018</td>\n",
       "      <td>Food whose production has been subsidized with...</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>These products come mainly from large enterpri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>E08019</td>\n",
       "      <td>Food whose production has been subsidized with...</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>Subsidies often make farmers in recipient coun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5392</th>\n",
       "      <td>E08020</td>\n",
       "      <td>The EU should integrate the armed forces of it...</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>The EU cannot endlessly lean on America or NAT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5393 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Argument ID                                         Conclusion  \\\n",
       "0         A01002                        We should ban human cloning   \n",
       "1         A01005                            We should ban fast food   \n",
       "2         A01006        We should end the use of economic sanctions   \n",
       "3         A01007               We should abolish capital punishment   \n",
       "4         A01008                      We should ban factory farming   \n",
       "...          ...                                                ...   \n",
       "5388      E08016  The EU should integrate the armed forces of it...   \n",
       "5389      E08017  Food whose production has been subsidized with...   \n",
       "5390      E08018  Food whose production has been subsidized with...   \n",
       "5391      E08019  Food whose production has been subsidized with...   \n",
       "5392      E08020  The EU should integrate the armed forces of it...   \n",
       "\n",
       "           Stance                                            Premise  label  \n",
       "0     in favor of  we should ban human cloning as it will only ca...      0  \n",
       "1     in favor of  fast food should be banned because it is reall...      0  \n",
       "2         against  sometimes economic sanctions are the only thin...      1  \n",
       "3         against  capital punishment is sometimes the only optio...      1  \n",
       "4         against  factory farming allows for the production of c...      1  \n",
       "...           ...                                                ...    ...  \n",
       "5388  in favor of  On the one hand, we have Russia killing countl...      0  \n",
       "5389  in favor of  The subsidies were originally intended to ensu...      0  \n",
       "5390  in favor of  These products come mainly from large enterpri...      0  \n",
       "5391  in favor of  Subsidies often make farmers in recipient coun...      0  \n",
       "5392  in favor of  The EU cannot endlessly lean on America or NAT...      0  \n",
       "\n",
       "[5393 rows x 5 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a19181f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:34:51.091807Z",
     "start_time": "2022-12-12T21:34:51.062818Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A01002    1\n",
      "A27361    1\n",
      "A27372    1\n",
      "A27371    1\n",
      "A27369    1\n",
      "         ..\n",
      "A21207    1\n",
      "A21206    1\n",
      "A21205    1\n",
      "A21204    1\n",
      "E08020    1\n",
      "Name: Argument ID, Length: 5393, dtype: int64\n",
      "\n",
      "0    4405\n",
      "1     988\n",
      "Name: Self-direction: thought, dtype: int64\n",
      "\n",
      "0    3998\n",
      "1    1395\n",
      "Name: Self-direction: action, dtype: int64\n",
      "\n",
      "0    5146\n",
      "1     247\n",
      "Name: Stimulation, dtype: int64\n",
      "\n",
      "0    5221\n",
      "1     172\n",
      "Name: Hedonism, dtype: int64\n",
      "\n",
      "0    3881\n",
      "1    1512\n",
      "Name: Achievement, dtype: int64\n",
      "\n",
      "0    4783\n",
      "1     610\n",
      "Name: Power: dominance, dtype: int64\n",
      "\n",
      "0    4768\n",
      "1     625\n",
      "Name: Power: resources, dtype: int64\n",
      "\n",
      "0    5011\n",
      "1     382\n",
      "Name: Face, dtype: int64\n",
      "\n",
      "0    3393\n",
      "1    2000\n",
      "Name: Security: personal, dtype: int64\n",
      "\n",
      "0    3665\n",
      "1    1728\n",
      "Name: Security: societal, dtype: int64\n",
      "\n",
      "0    4825\n",
      "1     568\n",
      "Name: Tradition, dtype: int64\n",
      "\n",
      "0    4216\n",
      "1    1177\n",
      "Name: Conformity: rules, dtype: int64\n",
      "\n",
      "0    5186\n",
      "1     207\n",
      "Name: Conformity: interpersonal, dtype: int64\n",
      "\n",
      "0    4998\n",
      "1     395\n",
      "Name: Humility, dtype: int64\n",
      "\n",
      "0    4061\n",
      "1    1332\n",
      "Name: Benevolence: caring, dtype: int64\n",
      "\n",
      "0    4587\n",
      "1     806\n",
      "Name: Benevolence: dependability, dtype: int64\n",
      "\n",
      "0    3312\n",
      "1    2081\n",
      "Name: Universalism: concern, dtype: int64\n",
      "\n",
      "0    4966\n",
      "1     427\n",
      "Name: Universalism: nature, dtype: int64\n",
      "\n",
      "0    4729\n",
      "1     664\n",
      "Name: Universalism: tolerance, dtype: int64\n",
      "\n",
      "0    4339\n",
      "1    1054\n",
      "Name: Universalism: objectivity, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in training_semlabels:\n",
    "    print(training_semlabels[x].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "501e75ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:34:51.532483Z",
     "start_time": "2022-12-12T21:34:51.523904Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_pairwise_input(feature_dataset: pd.DataFrame):\n",
    "    premises = feature_dataset['Premise'].to_list()\n",
    "    conclusions = feature_dataset['Conclusion'].to_list()\n",
    "    labels = feature_dataset['label'].to_list()\n",
    "    \n",
    "    return premises, conclusions, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec34abf",
   "metadata": {},
   "source": [
    "## Prep premises, conslusions, and stance labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "55cea7eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:34:52.975240Z",
     "start_time": "2022-12-12T21:34:52.956517Z"
    }
   },
   "outputs": [],
   "source": [
    "train_premises, train_conclusions, train_labels = generate_pairwise_input(training_arguments)\n",
    "val_premises, val_conclusions, val_labels = generate_pairwise_input(validation_arguments)\n",
    "# test_premises, test_conclusions, test_labels = generate_pairwise_input(test_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4f55f67b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:34:53.355883Z",
     "start_time": "2022-12-12T21:34:53.340284Z"
    }
   },
   "outputs": [],
   "source": [
    "test_premises = test_arguments[\"Premise\"].to_list()\n",
    "test_conclusions = test_arguments[\"Conclusion\"].to_list()\n",
    "test_labels = test_arguments[\"label\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31290184",
   "metadata": {},
   "source": [
    "## One hot encode the stance label for Neural net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8719606c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:34:54.030232Z",
     "start_time": "2022-12-12T21:34:54.013493Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "train_labels_ohe = ohe.fit_transform(np.asarray(train_labels).reshape(-1,1)).astype(int)\n",
    "val_labels_ohe = ohe.transform(np.asarray(val_labels).reshape(-1,1)).astype(int)\n",
    "test_labels_ohe = ohe.transform(np.asarray(test_labels).reshape(-1,1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "df019b5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:34:54.356268Z",
     "start_time": "2022-12-12T21:34:54.345151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5393"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "049ee9e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:34:54.778938Z",
     "start_time": "2022-12-12T21:34:54.764281Z"
    }
   },
   "outputs": [],
   "source": [
    "def chunk(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def chunk_multi(lst1, lst2, n):\n",
    "    for i in range(0, len(lst1), n):\n",
    "        yield lst1[i: i + n], lst2[i: i + n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fdfe8e",
   "metadata": {},
   "source": [
    "## Batch the Train, Validation, and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4cda39b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:34:57.625290Z",
     "start_time": "2022-12-12T21:34:55.963843Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "\n",
    "tokenizer = BatchTokenizer()\n",
    "\n",
    "train_input_batches = [b for b in chunk_multi(train_premises, train_conclusions, batch_size)]\n",
    "train_input_batches = [tokenizer(*batch) for batch in train_input_batches]\n",
    "\n",
    "val_input_batches = [b for b in chunk_multi(val_premises, val_conclusions, batch_size)]\n",
    "val_input_batches = [tokenizer(*batch) for batch in val_input_batches]\n",
    "\n",
    "test_input_batches = [b for b in chunk_multi(test_premises, test_conclusions, batch_size)]\n",
    "test_input_batches = [tokenizer(*batch) for batch in test_input_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "65645db7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:34:57.628565Z",
     "start_time": "2022-12-12T21:34:57.626581Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_multi_labels(labels) -> torch.FloatTensor:\n",
    "    \"\"\"Turns the batch of labels into a tensor\n",
    "\n",
    "    Args:\n",
    "        labels (List[int]): List of all labels in the batch\n",
    "\n",
    "    Returns:\n",
    "        torch.FloatTensor: Tensor of all labels in the batch\n",
    "    \"\"\"\n",
    "    return torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ee0057b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:35:01.941889Z",
     "start_time": "2022-12-12T21:35:01.929045Z"
    }
   },
   "outputs": [],
   "source": [
    "train_label1_batches = [b for b in chunk(train_labels_ohe, 200)]\n",
    "train_label1_batches = [encode_multi_labels(batch) for batch in train_label1_batches]\n",
    "\n",
    "val_label1_batches = [b for b in chunk(val_labels_ohe, 200)]\n",
    "val_label1_batches = [encode_multi_labels(batch) for batch in val_label1_batches]\n",
    "\n",
    "test_label1_batches = [b for b in chunk(test_labels_ohe, 200)]\n",
    "test_label1_batches = [encode_multi_labels(batch) for batch in test_label1_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "2552ffff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:35:03.184646Z",
     "start_time": "2022-12-12T21:35:03.171255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 2])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label1_batches[0].shape # check to ensure correct size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e9114c",
   "metadata": {},
   "source": [
    "### Selecting which labels to predict\n",
    "\n",
    "In the first cell, it is the labels with the more even representation, in the second cell it is all 20 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2be653c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:35:07.945425Z",
     "start_time": "2022-12-12T21:35:07.930613Z"
    }
   },
   "outputs": [],
   "source": [
    "## Subset of labels\n",
    "use_training_labels = training_semlabels.loc[:,[\"Self-direction: action\", \n",
    "                                             \"Security: personal\", \n",
    "                                             \"Universalism: concern\"]].values.copy()\n",
    "use_validation_labels = validation_semlabels.loc[:,[\"Self-direction: action\", \n",
    "                                                 \"Security: personal\", \n",
    "                                                 \"Universalism: concern\"]].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "07f25fe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:35:09.170301Z",
     "start_time": "2022-12-12T21:35:09.167137Z"
    }
   },
   "outputs": [],
   "source": [
    "## All labels\n",
    "# use_training_labels = training_semlabels.iloc[:,1:].values.copy()\n",
    "# use_validation_labels = validation_semlabels.iloc[:,1:].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "348648ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:35:09.371403Z",
     "start_time": "2022-12-12T21:35:09.363180Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def predict(model: torch.nn.Module, sents: torch.Tensor) -> List:\n",
    "    logits = model(sents)\n",
    "    return list(torch.argmax(logits, axis=2).squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "df600f47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:35:09.795300Z",
     "start_time": "2022-12-12T21:35:09.789524Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_mult(model: torch.nn.Module, sents: torch.Tensor) -> List:\n",
    "    logits = model(sents)\n",
    "    logits = logits.detach().numpy()\n",
    "    mask_30  = (logits > 0.5)\n",
    "    return mask_30.reshape(mask_30.shape[0], mask_30.shape[2]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b5763b",
   "metadata": {},
   "source": [
    "# Naive Model 1\n",
    "\n",
    "In this model, the data is first squeezed into two categories, then these predictions are added to the training sentences as extra features, which then goes through another sequence of layers to predict the labels from the 20 available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "008fb026",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:35:12.418486Z",
     "start_time": "2022-12-12T21:35:12.400734Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class NaiveClassifier(torch.nn.Module):\n",
    "    def __init__(self, output_size1: int, output_size2: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.output_size1 = output_size1\n",
    "        self.output_size2 = output_size2\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Initialize BERT, which we use instead of a single embedding layer.\n",
    "        self.bert = BertModel.from_pretrained(\"prajjwal1/bert-small\")\n",
    "        # Uncommenting out the below 2 lines means only our classification layer will be updated.\n",
    "        # for param in self.bert.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        self.bert_hidden_dimension = self.bert.config.hidden_size\n",
    "        \n",
    "        # create LSTM hidden layer\n",
    "        self.hidden_layer = torch.nn.LSTM(self.bert_hidden_dimension, \n",
    "                                         self.hidden_size)\n",
    "        # use ReLU for input to first classifier\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.classifier1 = torch.nn.Linear(self.hidden_size, self.output_size1)\n",
    "        # Log softmax for binary classification (are premise/conslusion in support)\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=2)\n",
    "        # Sigmoid for multi-label prediction\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.hidden_layer2 = torch.nn.LSTM(self.bert_hidden_dimension + 2,\n",
    "                                          self.hidden_size)\n",
    "        self.classifier2 = torch.nn.Linear(self.hidden_size, self.output_size2)\n",
    "\n",
    "\n",
    "    def encode_text(\n",
    "        self,\n",
    "        symbols: Dict\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Encode the (batch of) sequence(s) of token symbols with an LSTM.\n",
    "            Then, get the last (non-padded) hidden state for each symbol and return that.\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The final hiddens tate of the LSTM, which represents an encoding of\n",
    "                the entire sentence\n",
    "        \"\"\"\n",
    "        # First we get the contextualized embedding for each input symbol\n",
    "        # We no longer need an LSTM, since BERT encodes context and \n",
    "        # gives us a single vector describing the sequence in the form of the [CLS] token.\n",
    "        encoded_sequence = self.bert(**symbols)\n",
    "\n",
    "        # We want to return a tensor of the form batch_size x 1 x bert_hidden_dimension\n",
    "        curr_batch = encoded_sequence['pooler_output'].shape[0]\n",
    "        pooler_output = encoded_sequence['pooler_output'][:].reshape((curr_batch,\n",
    "                                                                      1, \n",
    "                                                                      self.bert_hidden_dimension))\n",
    "        \n",
    "        return pooler_output\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        symbols: Dict,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: _description_\n",
    "        \"\"\"\n",
    "        encoded_sents = self.encode_text(symbols)\n",
    "        # print(encoded_sents.shape)\n",
    "        output = self.hidden_layer(encoded_sents)\n",
    "        # print(output[0].shape)\n",
    "        output = self.relu(output[0])\n",
    "        # print(output.shape)\n",
    "        output = self.classifier1(output)\n",
    "        # print(output.shape)\n",
    "        # print(output[:5])\n",
    "        first_res = self.log_softmax(output)\n",
    "        # print(first_res.shape)\n",
    "        new_data = torch.cat((encoded_sents, first_res), 2)\n",
    "        output2 = self.hidden_layer2(new_data)\n",
    "        output2 = self.relu(output2[0])\n",
    "        output2 = self.classifier2(output2)\n",
    "        second_res = self.log_softmax(output2)\n",
    "        return second_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "221936b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:35:13.470550Z",
     "start_time": "2022-12-12T21:35:13.453306Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def training_loop_single_model(\n",
    "    num_epochs,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    dev_sents,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    model,\n",
    "):\n",
    "    print(\"Training...\")\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    batches = list(zip(train_features, train_labels))\n",
    "    random.shuffle(batches)\n",
    "    for i in range(num_epochs):\n",
    "        losses = []\n",
    "        for features, labels in tqdm(batches):\n",
    "            # Empty the dynamic computation graph\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(features).squeeze(1)\n",
    "            loss = loss_func(preds, labels.float())\n",
    "            # Backpropogate the loss through our model\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        print(f\"epoch {i}, loss: {sum(losses)/len(losses)}\")\n",
    "        # Estimate the f1 score for the development set\n",
    "        print(\"Evaluating dev...\")\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        for sents, labels in tqdm(zip(dev_sents, dev_labels), total=len(dev_sents)):\n",
    "            pred = predict(model, sents)\n",
    "            all_preds.extend(pred)\n",
    "            all_labels.extend(list(labels.numpy()))\n",
    "        \n",
    "        all_labels = np.asarray(all_labels)\n",
    "        preds = np.zeros((len(all_preds), all_labels.shape[1]))\n",
    "        for i, x in enumerate(all_preds):\n",
    "            preds[i,x] = 1\n",
    "        dev_f1 = f1_score(preds, all_labels, average='macro')\n",
    "        print(f\"Dev F1 {dev_f1}\")\n",
    "        \n",
    "    # Return the trained model\n",
    "    return model, all_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8afccb",
   "metadata": {},
   "source": [
    "## Using 3 labels\n",
    "\n",
    "The labels included here are \"Self-direction: action\", \"Security: personal\", and \"Universalism: concern\". These labels had more in-class examples than others, which is why they were chosen. \n",
    "\n",
    "Considering we were using 3 labels, it is assumed that a random classifier would return a $33\\%$ F1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "45768d28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:35:14.868797Z",
     "start_time": "2022-12-12T21:35:14.861186Z"
    }
   },
   "outputs": [],
   "source": [
    "partial_train_semlabel_batches = [b for b in chunk(use_training_labels, 200)]\n",
    "partial_train_semlabel_batches = [encode_multi_labels(batch) for batch in partial_train_semlabel_batches]\n",
    "\n",
    "partial_val_semlabel_batches = [b for b in chunk(use_validation_labels, 200)]\n",
    "partial_val_semlabel_batches = [encode_multi_labels(batch) for batch in partial_val_semlabel_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c65096dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:49:20.135361Z",
     "start_time": "2022-12-12T21:35:15.827629Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:48<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 0.6589264339870877\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.30807286809553713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:49<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.6513857245445251\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.3134008144559192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:48<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss: 0.6466759818571585\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.32617248977022345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss: 0.6422582003805373\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.341711978141453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss: 0.6377479544392338\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.34933984762555026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:50<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, loss: 0.6335846075305233\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.351390311831923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:49<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, loss: 0.6301020163076895\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.36151483135346857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:48<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, loss: 0.6270202795664469\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.36986237741888317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:49<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, loss: 0.6237730229342425\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.38727773947802085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:48<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, loss: 0.6195213441495542\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.4105663085588245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:48<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, loss: 0.6149783222763626\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.4285263695798422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:48<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, loss: 0.6108479212831568\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.44589970642828086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:48<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, loss: 0.6055799987581041\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.4568677343241678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:48<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, loss: 0.6014458228040624\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.4676237683569373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:49<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, loss: 0.5978190656061526\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.4727143341487068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# You can increase epochs if need be\n",
    "epochs = 15\n",
    "# TODO: Find a good learning rate\n",
    "LR = 0.00001 / 2\n",
    "\n",
    "possible_labels = train_labels_ohe.shape[1]\n",
    "naive_model = NaiveClassifier(output_size1=possible_labels,\n",
    "                              output_size2=partial_train_semlabel_batches[0].shape[1], \n",
    "                              hidden_size=25)\n",
    "optimizer = torch.optim.AdamW(naive_model.parameters(), LR)\n",
    "\n",
    "naive_model, all_preds = training_loop_single_model(\n",
    "    epochs,\n",
    "    train_input_batches,\n",
    "    partial_train_semlabel_batches,\n",
    "    val_input_batches,\n",
    "    partial_val_semlabel_batches,\n",
    "    optimizer,\n",
    "    naive_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2198cc6e",
   "metadata": {},
   "source": [
    "### Final F1 score\n",
    "\n",
    "The highest F1 score achieved for the partial label naive model was $49\\%$, and the lowest was $36\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3105e1b",
   "metadata": {},
   "source": [
    "## Using full labels\n",
    "\n",
    "Now we will train the same model, but this time using all the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "dd115b1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:50:06.714005Z",
     "start_time": "2022-12-12T21:50:06.701202Z"
    }
   },
   "outputs": [],
   "source": [
    "full_training_labels = training_semlabels.iloc[:,1:].values.copy()\n",
    "full_validation_labels = validation_semlabels.iloc[:,1:].values.copy()\n",
    "\n",
    "train_semlabel_batches = [b for b in chunk(full_training_labels, 200)]\n",
    "train_semlabel_batches = [encode_multi_labels(batch) for batch in train_semlabel_batches]\n",
    "\n",
    "val_semlabel_batches = [b for b in chunk(full_validation_labels, 200)]\n",
    "val_semlabel_batches = [encode_multi_labels(batch) for batch in val_semlabel_batches]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa974a6d",
   "metadata": {},
   "source": [
    "### Adjust the activation layer\n",
    "\n",
    "New activation layer is sigmoid, which will return values $\\in[0,1]$ to be used for multilabel (get all labels above a threshold). This is reflected in the `predict_mult` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2b704d48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T21:50:13.610061Z",
     "start_time": "2022-12-12T21:50:13.591408Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class NaiveMultiClass(torch.nn.Module):\n",
    "    def __init__(self, output_size1: int, output_size2: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.output_size1 = output_size1\n",
    "        self.output_size2 = output_size2\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Initialize BERT, which we use instead of a single embedding layer.\n",
    "        self.bert = BertModel.from_pretrained(\"prajjwal1/bert-small\")\n",
    "        # Uncommenting out the below 2 lines means only our classification layer will be updated.\n",
    "        # for param in self.bert.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        self.bert_hidden_dimension = self.bert.config.hidden_size\n",
    "        \n",
    "        # create LSTM hidden layer\n",
    "        self.hidden_layer = torch.nn.LSTM(self.bert_hidden_dimension, \n",
    "                                         self.hidden_size)\n",
    "        # use ReLU for input to first classifier\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.classifier1 = torch.nn.Linear(self.hidden_size, self.output_size1)\n",
    "        # Log softmax for binary classification (are premise/conslusion in support)\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=2)\n",
    "        # Sigmoid for multi-label prediction\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.hidden_layer2 = torch.nn.LSTM(self.bert_hidden_dimension + 2,\n",
    "                                          self.hidden_size)\n",
    "        self.classifier2 = torch.nn.Linear(self.hidden_size, self.output_size2)\n",
    "\n",
    "\n",
    "    def encode_text(\n",
    "        self,\n",
    "        symbols: Dict\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Encode the (batch of) sequence(s) of token symbols with an LSTM.\n",
    "            Then, get the last (non-padded) hidden state for each symbol and return that.\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The final hiddens tate of the LSTM, which represents an encoding of\n",
    "                the entire sentence\n",
    "        \"\"\"\n",
    "        # First we get the contextualized embedding for each input symbol\n",
    "        # We no longer need an LSTM, since BERT encodes context and \n",
    "        # gives us a single vector describing the sequence in the form of the [CLS] token.\n",
    "        encoded_sequence = self.bert(**symbols)\n",
    "\n",
    "        # We want to return a tensor of the form batch_size x 1 x bert_hidden_dimension\n",
    "        curr_batch = encoded_sequence['pooler_output'].shape[0]\n",
    "        pooler_output = encoded_sequence['pooler_output'][:].reshape((curr_batch,\n",
    "                                                                      1, \n",
    "                                                                      self.bert_hidden_dimension))\n",
    "        \n",
    "        return pooler_output\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        symbols: Dict,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: _description_\n",
    "        \"\"\"\n",
    "        encoded_sents = self.encode_text(symbols)\n",
    "        # print(encoded_sents.shape)\n",
    "        output = self.hidden_layer(encoded_sents)\n",
    "        # print(output[0].shape)\n",
    "        output = self.relu(output[0])\n",
    "        # print(output.shape)\n",
    "        output = self.classifier1(output)\n",
    "        # print(output.shape)\n",
    "        # print(output[:5])\n",
    "        first_res = self.log_softmax(output)\n",
    "        # print(first_res.shape)\n",
    "        new_data = torch.cat((encoded_sents, first_res), 2)\n",
    "        output2 = self.hidden_layer2(new_data)\n",
    "        output2 = self.relu(output2[0])\n",
    "        output2 = self.classifier2(output2)\n",
    "        second_res = self.sigmoid(output2)\n",
    "        return second_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "f97bb87a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:45:23.530962Z",
     "start_time": "2022-12-12T22:45:23.514359Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def training_loop_single_model(\n",
    "    num_epochs,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    dev_sents,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    model,\n",
    "):\n",
    "    print(\"Training...\")\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    batches = list(zip(train_features, train_labels))\n",
    "    random.shuffle(batches)\n",
    "    for i in range(num_epochs):\n",
    "        losses = []\n",
    "        for features, labels in tqdm(batches):\n",
    "            # Empty the dynamic computation graph\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(features).squeeze(1)\n",
    "\n",
    "            loss = loss_func(preds, labels.float())\n",
    "            # Backpropogate the loss through our model\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        print(f\"epoch {i}, loss: {sum(losses)/len(losses)}\")\n",
    "        # Estimate the f1 score for the development set\n",
    "        print(\"Evaluating dev...\")\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        for sents, labels in tqdm(zip(dev_sents, dev_labels), total=len(dev_sents)):\n",
    "            pred = predict(model, sents)\n",
    "            all_preds.extend(pred)\n",
    "            all_labels.extend(list(labels.numpy()))\n",
    "        \n",
    "        all_labels = np.asarray(all_labels)\n",
    "        preds = np.zeros((len(all_preds), all_labels.shape[1]))\n",
    "        for i, x in enumerate(all_preds):\n",
    "            preds[i,x] = 1\n",
    "        dev_f1 = f1_score(preds, all_labels, average='macro')\n",
    "        print(f\"Dev F1 {dev_f1}\")\n",
    "        \n",
    "    # Return the trained model\n",
    "    return model, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "3385f9c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:45:42.223807Z",
     "start_time": "2022-12-12T22:45:23.976061Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████▎                                                                                                                                         | 1/27 [00:04<01:51,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██████████▌                                                                                                                                    | 2/27 [00:05<01:05,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|███████████████▉                                                                                                                               | 3/27 [00:07<00:48,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████████████████████▏                                                                                                                         | 4/27 [00:08<00:40,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|██████████████████████████▍                                                                                                                    | 5/27 [00:12<00:54,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|███████████████████████████████▊                                                                                                               | 6/27 [00:14<00:52,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████████████████████                                                                                                          | 7/27 [00:16<00:42,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████████████████████▎                                                                                                    | 8/27 [00:17<00:41,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w9/9_db973n5ds10v87c_99j_g00000gn/T/ipykernel_66895/2067799487.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnaive_model2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m naive_model2, all_preds = training_loop_single_model(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_input_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/w9/9_db973n5ds10v87c_99j_g00000gn/T/ipykernel_66895/1835274791.py\u001b[0m in \u001b[0;36mtraining_loop_single_model\u001b[0;34m(num_epochs, train_features, train_labels, dev_sents, dev_labels, optimizer, model)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Empty the dynamic computation graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/w9/9_db973n5ds10v87c_99j_g00000gn/T/ipykernel_66895/944391531.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, symbols)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_description_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mencoded_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;31m# print(encoded_sents.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/w9/9_db973n5ds10v87c_99j_g00000gn/T/ipykernel_66895/944391531.py\u001b[0m in \u001b[0;36mencode_text\u001b[0;34m(self, symbols)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# We no longer need an LSTM, since BERT encodes context and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# gives us a single vector describing the sequence in the form of the [CLS] token.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mencoded_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# We want to return a tensor of the form batch_size x 1 x bert_hidden_dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n\u001b[0;32m-> 1014\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    601\u001b[0m                 )\n\u001b[1;32m    602\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    604\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 419\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    420\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_query_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "LR = 5e-6\n",
    "\n",
    "possible_labels = train_labels_ohe.shape[1]\n",
    "naive_model2 = NaiveMultiClass(output_size1=possible_labels,\n",
    "                              output_size2=train_semlabel_batches[0].shape[1], \n",
    "                              hidden_size=25)\n",
    "optimizer = torch.optim.AdamW(naive_model2.parameters(), LR)\n",
    "\n",
    "naive_model2, all_preds = training_loop_single_model(\n",
    "    epochs,\n",
    "    train_input_batches,\n",
    "    train_semlabel_batches,\n",
    "    val_input_batches,\n",
    "    val_semlabel_batches,\n",
    "    optimizer,\n",
    "    naive_model2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0cd126",
   "metadata": {},
   "source": [
    "# Dual Model Approach\n",
    "\n",
    "In this approach I will attempt to use two models, the first will be a model that predicts if a conclusion supports or is against its premise. From here, the second model will take as input the same premise/conclusions, but will use the labels from the first model to inform the second model.\n",
    "\n",
    "\n",
    "\n",
    "## Rough sketch of how the ideal system would work\n",
    "![model_sketch](https://www.imgur.com/iYkVRq6.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "42a19e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T23:10:57.381520Z",
     "start_time": "2022-12-12T23:10:57.360417Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class NLIClassifier(torch.nn.Module):\n",
    "    def __init__(self, output_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Initialize BERT, which we use instead of a single embedding layer.\n",
    "        self.bert = BertModel.from_pretrained(\"prajjwal1/bert-small\")\n",
    "        # self.bert = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\",)\n",
    "        # Uncommenting out the below 2 lines means only our classification layer will be updated.\n",
    "        # for param in self.bert.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        self.bert_hidden_dimension = self.bert.config.hidden_size\n",
    "        # TODO: Add an extra hidden layer in the classifier, projecting\n",
    "        #      from the BERT hidden dimension to hidden size.\n",
    "        self.hidden_layer = torch.nn.LSTM(self.bert_hidden_dimension, \n",
    "                                         self.hidden_size)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.classifier = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=2)\n",
    "\n",
    "\n",
    "    def encode_text(\n",
    "        self,\n",
    "        symbols: Dict\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Encode the (batch of) sequence(s) of token symbols with an LSTM.\n",
    "            Then, get the last (non-padded) hidden state for each symbol and return that.\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The final hiddens tate of the LSTM, which represents an encoding of\n",
    "                the entire sentence\n",
    "        \"\"\"\n",
    "        # First we get the contextualized embedding for each input symbol\n",
    "        # We no longer need an LSTM, since BERT encodes context and \n",
    "        # gives us a single vector describing the sequence in the form of the [CLS] token.\n",
    "        encoded_sequence = self.bert(**symbols)\n",
    "\n",
    "        # We want to return a tensor of the form batch_size x 1 x bert_hidden_dimension\n",
    "        curr_batch = encoded_sequence['pooler_output'].shape[0]\n",
    "        pooler_output = encoded_sequence['pooler_output'][:].reshape((curr_batch,\n",
    "                                                                      1, \n",
    "                                                                      self.bert_hidden_dimension))\n",
    "        \n",
    "        return pooler_output\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        symbols: Dict,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: _description_\n",
    "        \"\"\"\n",
    "        encoded_sents = self.encode_text(symbols)\n",
    "        output = self.hidden_layer(encoded_sents)\n",
    "        output = self.relu(output[0])\n",
    "        output = self.classifier(output)\n",
    "        output = self.log_softmax(output) #[200, 1, 2]\n",
    "        return output #self.log_softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "b8290be7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T04:35:52.065206Z",
     "start_time": "2022-12-13T04:35:52.035349Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class semClassifier(torch.nn.Module):\n",
    "    def __init__(self, output_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Initialize BERT, which we use instead of a single embedding layer.\n",
    "        self.bert = BertForPreTraining.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\",\n",
    "                                                                  output_hidden_states=True)\n",
    "        self.bert.config.num_labels = self.output_size\n",
    "        # Uncommenting out the below 2 lines means only our classification layer will be updated.\n",
    "        # for param in self.bert.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        self.bert_hidden_dimension = self.bert.config.hidden_size\n",
    "        # TODO: Add an extra hidden layer in the classifier, projecting\n",
    "        #      from the BERT hidden dimension to hidden size.\n",
    "        self.hidden_layer = torch.nn.LSTM(self.bert_hidden_dimension, \n",
    "                                         self.hidden_size)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.classifier = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def encode_text(\n",
    "        self,\n",
    "        symbols: Dict\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Encode the (batch of) sequence(s) of token symbols with an LSTM.\n",
    "            Then, get the last (non-padded) hidden state for each symbol and return that.\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The final hiddens tate of the LSTM, which represents an encoding of\n",
    "                the entire sentence\n",
    "        \"\"\"\n",
    "        # First we get the contextualized embedding for each input symbol\n",
    "        # We no longer need an LSTM, since BERT encodes context and \n",
    "        # gives us a single vector describing the sequence in the form of the [CLS] token.\n",
    "        encoded_sequence = self.bert(**symbols)\n",
    "        # print(encoded_sequence['prediction_logits'].shape)\n",
    "        # # We want to return a tensor of the form batch_size x 1 x bert_hidden_dimension\n",
    "        # for x in encoded_sequence['hidden_states']:\n",
    "        #     print(x.shape)\n",
    "        # curr_batch = encoded_sequence['hidden_states'][0].shape[0]\n",
    "        # ret_val = encoded_sequence['hidden_states'][:,].reshape((curr_batch,\n",
    "        #                                                               1, \n",
    "        #                                                               self.bert_hidden_dimension))\n",
    "        \n",
    "        # return the last hidden state's \n",
    "        # print(encoded_sequence['logits'].shape)\n",
    "        return encoded_sequence['hidden_states'][-1][:,-1,:]\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        symbols: Dict,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: _description_\n",
    "        \"\"\"\n",
    "        encoded_sents = self.encode_text(symbols)\n",
    "        # print(len(encoded_sents))\n",
    "        # print(encoded_sents.shape)\n",
    "        output = self.hidden_layer(encoded_sents)\n",
    "        output = self.relu(output[0])\n",
    "        output = self.classifier(output) \n",
    "        return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "c877e2f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T04:35:52.714596Z",
     "start_time": "2022-12-13T04:35:52.681138Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "def predict(model: torch.nn.Module, sents: torch.Tensor) -> List:\n",
    "    logits = model(sents)\n",
    "    return list(torch.argmax(logits, axis=1).squeeze().numpy())\n",
    "\n",
    "def training_loop_dual_model(\n",
    "    num_epochs,\n",
    "    train_features,\n",
    "    train_labels1,\n",
    "    train_labels2,\n",
    "    dev_sents,\n",
    "    dev_labels1,\n",
    "    dev_labels2,\n",
    "    optimizer1,\n",
    "    optimizer2,\n",
    "    model1,\n",
    "    model2,\n",
    "):\n",
    "    # print(\"Training...\")\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    nli_batches = list(zip(train_features, train_labels1))\n",
    "    sem_batches = list(zip(train_features, train_labels2))\n",
    "    random.shuffle(nli_batches)\n",
    "    random.shuffle(sem_batches)\n",
    "    for i in range(num_epochs):\n",
    "        model_1_losses = []\n",
    "        model_1_preds = []\n",
    "        print(\"Training Model 1...\")\n",
    "        # first train the model to predict whether or not a \n",
    "        for features, labels in tqdm(nli_batches):\n",
    "            # Empty the dynamic computation graph\n",
    "            optimizer1.zero_grad()\n",
    "            preds = model1(features).squeeze(1)\n",
    "            # print(preds.shape)\n",
    "            loss = loss_func(preds, labels.float())\n",
    "            fw_preds = list(torch.argmax(preds, axis=1).numpy())\n",
    "            model_1_preds.append(fw_preds)\n",
    "            \n",
    "            # Backpropogate the loss through our model\n",
    "            loss.backward()\n",
    "            optimizer1.step()\n",
    "            model_1_losses.append(loss.item())\n",
    "        \n",
    "        print(f\"epoch {i}, model 1 loss: {sum(model_1_losses)/len(model_1_losses)}\")\n",
    "        \n",
    "        print(\"Training Model 2...\")\n",
    "        model_2_losses = []\n",
    "        for (features, labels), m1_preds in tqdm(zip(sem_batches, model_1_preds), total=len(sem_batches)):\n",
    "            # Empty the dynamic computation graph\n",
    "            optimizer2.zero_grad()\n",
    "            these_features = deepcopy(features)\n",
    "            these_features['next_sentence_label'] = m1_preds\n",
    "            preds = model2(these_features).squeeze(1)\n",
    "            loss = loss_func(preds, labels.float())\n",
    "            # Backpropogate the loss through our model\n",
    "            loss.backward()\n",
    "            optimizer2.step()\n",
    "            model_2_losses.append(loss.item())\n",
    "        \n",
    "        print(f\"epoch {i}, model 2 loss: {sum(model_2_losses)/len(model_2_losses)}\")\n",
    "        # Estimate the f1 score for the development set\n",
    "        print(\"Evaluating model 1 dev...\")\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        for sents, labels in tqdm(zip(dev_sents, dev_labels1), total=len(dev_sents)):\n",
    "            pred = predict(model1, sents)\n",
    "            all_preds.extend(pred)\n",
    "            all_labels.extend(list(labels.numpy()))\n",
    "        \n",
    "        all_labels = np.asarray(all_labels)\n",
    "        preds = np.zeros((len(all_preds), all_labels.shape[1]))\n",
    "        for i, x in enumerate(all_preds):\n",
    "            preds[i,x] = 1\n",
    "        dev_f1 = f1_score(np.asarray(preds), np.asarray(all_labels), average='macro')\n",
    "        print(f\"Model 1 Dev F1 {dev_f1}\")\n",
    "        \n",
    "        print(\"Evaluating model 2 dev...\")\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        for sents, labels in tqdm(zip(dev_sents, dev_labels2), total=len(dev_sents)):\n",
    "            pred = predict(model2, sents)\n",
    "            all_preds.extend(pred)\n",
    "            all_labels.extend(list(labels.numpy()))\n",
    "        \n",
    "        all_labels = np.asarray(all_labels)\n",
    "        preds = np.zeros((len(all_preds), all_labels.shape[1]))\n",
    "        for i, x in enumerate(all_preds):\n",
    "            preds[i,x] = 1\n",
    "        dev_f1 = f1_score(np.asarray(preds), np.asarray(all_labels), average='macro')\n",
    "        print(f\"Model 2 Dev F1 {dev_f1}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Return the trained model\n",
    "    return model2, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "8010893c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T06:21:44.401006Z",
     "start_time": "2022-12-13T04:35:53.189057Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at textattack/bert-base-uncased-yelp-polarity were not used when initializing BertForPreTraining: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertForPreTraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForPreTraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForPreTraining were not initialized from the model checkpoint at textattack/bert-base-uncased-yelp-polarity and are newly initialized: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, model 1 loss: 0.7479404674635993\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:24<00:00, 12.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, model 2 loss: 0.7964820508603696\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:49<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.2346310399195394\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, model 1 loss: 0.7425192462073432\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:13<00:00, 11.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, model 2 loss: 0.7801737895718327\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:49<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.19004524886877827\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, model 1 loss: 0.7351205061983179\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:14<00:00, 11.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, model 2 loss: 0.7679965628517998\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:53<00:00,  5.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.19058380414312617\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, model 1 loss: 0.7200098788296735\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:16<00:00, 11.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, model 2 loss: 0.7667410439915128\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:49<00:00,  4.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.19058380414312617\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, model 1 loss: 0.6972201908076251\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:17<00:00, 11.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, model 2 loss: 0.7641634941101074\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:54<00:00,  5.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.19058380414312617\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, model 1 loss: 0.673562056488461\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:18<00:00, 11.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, model 2 loss: 0.762462646872909\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:51<00:00,  5.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.19058380414312617\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, model 1 loss: 0.6498162459444117\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:12<00:00, 11.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, model 2 loss: 0.7621609811429624\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:51<00:00,  5.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.19058380414312617\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, model 1 loss: 0.6251550206431636\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:09<00:00, 11.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, model 2 loss: 0.7611874938011169\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:49<00:00,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.1911924884992043\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, model 1 loss: 0.6044662727249993\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:10<00:00, 11.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, model 2 loss: 0.7577201105930187\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:54<00:00,  5.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.19058380414312617\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, model 1 loss: 0.5926414529482523\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:19<00:00, 11.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, model 2 loss: 0.7561980706674082\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:57<00:00,  5.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.19058380414312617\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, model 1 loss: 0.5751152744999638\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:17<00:00, 11.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, model 2 loss: 0.755180714307008\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:53<00:00,  5.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.1916950641996692\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, model 1 loss: 0.5679795918641267\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:17<00:00, 11.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, model 2 loss: 0.7536463450502466\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:48<00:00,  4.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.24899708105680715\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, model 1 loss: 0.583836782861639\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:10<00:00, 11.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, model 2 loss: 0.7515202804848\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:50<00:00,  5.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.3478398755665688\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, model 1 loss: 0.5593682924906412\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:20<00:00, 11.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, model 2 loss: 0.7496696004161129\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:53<00:00,  5.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.3499804528236064\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, model 1 loss: 0.5667349232567681\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:18<00:00, 11.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, model 2 loss: 0.748737410262779\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:54<00:00,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.312348178533633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# You can increase epochs if need be\n",
    "epochs = 15\n",
    "# TODO: Find a good learning rate\n",
    "LR = 0.00001\n",
    "\n",
    "possible_labels1 = train_labels_ohe.shape[1]\n",
    "model1 = NLIClassifier(output_size=possible_labels1, \n",
    "                       hidden_size=25)\n",
    "optimizer1 = torch.optim.AdamW(model1.parameters(), LR)\n",
    "\n",
    "possible_labels2 = partial_train_semlabel_batches[0].shape[1]\n",
    "model2 = semClassifier(output_size=possible_labels2,\n",
    "                       hidden_size=40)\n",
    "optimizer2 = torch.optim.AdamW(model2.parameters(), LR)\n",
    "\n",
    "# validation_input_batches = [b for b in chunk_multi(val_premises, val_conclusions, 200)]\n",
    "# # Tokenize + encode\n",
    "# validation_input_batches = [tokenizer(*batch) for batch in validation_input_batches]\n",
    "# validation_batch_labels = [b for b in chunk(val_labels, 200)]\n",
    "# validation_batch_labels = [encode_labels(batch) for batch in validation_batch_labels]\n",
    "\n",
    "\n",
    "model, all_preds = training_loop_dual_model(\n",
    "    epochs,\n",
    "    train_input_batches,\n",
    "    train_label1_batches,\n",
    "    partial_train_semlabel_batches,\n",
    "    val_input_batches,\n",
    "    val_label1_batches,\n",
    "    partial_val_semlabel_batches,\n",
    "    optimizer1,\n",
    "    optimizer2,\n",
    "    model1,\n",
    "    model2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "6f73f805",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-13T08:06:45.178748Z",
     "start_time": "2022-12-13T06:21:44.426595Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at textattack/bert-base-uncased-yelp-polarity were not used when initializing BertForPreTraining: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertForPreTraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForPreTraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForPreTraining were not initialized from the model checkpoint at textattack/bert-base-uncased-yelp-polarity and are newly initialized: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, model 1 loss: 0.750938406697026\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:19<00:00, 11.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, model 2 loss: 0.8921622987146731\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:53<00:00,  5.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.018990159167211675\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, model 1 loss: 0.747877335106885\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:09<00:00, 11.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, model 2 loss: 0.8866917954550849\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:50<00:00,  5.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.018651708728263938\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, model 1 loss: 0.7455261040616918\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:18<00:00, 11.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, model 2 loss: 0.8807923661337959\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:53<00:00,  5.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.02263043816573761\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, model 1 loss: 0.7429358076166224\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:15<00:00, 11.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, model 2 loss: 0.8776024557926037\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:51<00:00,  5.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.011201565530184698\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, model 1 loss: 0.7401190885791072\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:25<00:00, 12.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, model 2 loss: 0.8769587366669266\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:52<00:00,  5.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.00947770302452965\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:48<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, model 1 loss: 0.7364742800041482\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:13<00:00, 11.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, model 2 loss: 0.8766894141832987\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:49<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.009491773329648016\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, model 1 loss: 0.7302813353361907\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:11<00:00, 11.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, model 2 loss: 0.8764740493562486\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:52<00:00,  5.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.008518321168293663\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, model 1 loss: 0.7213944594065348\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:17<00:00, 11.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, model 2 loss: 0.8762784821015818\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:54<00:00,  5.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.00851766685643095\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, model 1 loss: 0.7108994214623062\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:16<00:00, 11.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, model 2 loss: 0.8760943854296649\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:52<00:00,  5.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.00851765082379787\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:47<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, model 1 loss: 0.6998388988000376\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:15<00:00, 11.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, model 2 loss: 0.8759184590092411\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:49<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.007762542026501416\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:46<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, model 1 loss: 0.68869505988227\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:06<00:00, 11.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, model 2 loss: 0.8756571699071813\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:49<00:00,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.015015346874350017\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:46<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, model 1 loss: 0.6777854164441427\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:08<00:00, 11.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, model 2 loss: 0.8751913397400467\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:49<00:00,  5.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.016371681415929203\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:46<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, model 1 loss: 0.6668630308575101\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:07<00:00, 11.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, model 2 loss: 0.8749566321019773\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:50<00:00,  5.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.01637246248896734\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:46<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, model 1 loss: 0.6558711881990786\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:10<00:00, 11.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, model 2 loss: 0.8747586056038186\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:50<00:00,  5.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.01637246248896734\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:46<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, model 1 loss: 0.6463159675951358\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [05:11<00:00, 11.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, model 2 loss: 0.8745663850395767\n",
      "Evaluating model 1 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Dev F1 0.35815842924847663\n",
      "Evaluating model 2 dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:49<00:00,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Dev F1 0.016379690949227373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# You can increase epochs if need be\n",
    "epochs = 15\n",
    "# TODO: Find a good learning rate\n",
    "LR = 5e-6\n",
    "\n",
    "possible_labels1 = train_labels_ohe.shape[1]\n",
    "model1 = NLIClassifier(output_size=possible_labels1, \n",
    "                       hidden_size=25)\n",
    "optimizer1 = torch.optim.AdamW(model1.parameters(), LR)\n",
    "\n",
    "possible_labels2 = train_semlabel_batches[0].shape[1]\n",
    "model2 = semClassifier(output_size=possible_labels2,\n",
    "                       hidden_size=40)\n",
    "optimizer2 = torch.optim.AdamW(model2.parameters(), LR)\n",
    "\n",
    "# validation_input_batches = [b for b in chunk_multi(val_premises, val_conclusions, 200)]\n",
    "# # Tokenize + encode\n",
    "# validation_input_batches = [tokenizer(*batch) for batch in validation_input_batches]\n",
    "# validation_batch_labels = [b for b in chunk(val_labels, 200)]\n",
    "# validation_batch_labels = [encode_labels(batch) for batch in validation_batch_labels]\n",
    "\n",
    "\n",
    "model, all_preds = training_loop_dual_model(\n",
    "    epochs,\n",
    "    train_input_batches,\n",
    "    train_label1_batches,\n",
    "    train_semlabel_batches,\n",
    "    val_input_batches,\n",
    "    val_label1_batches,\n",
    "    val_semlabel_batches,\n",
    "    optimizer1,\n",
    "    optimizer2,\n",
    "    model1,\n",
    "    model2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b8ba5",
   "metadata": {},
   "source": [
    "## Test set on models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "09080b6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T03:44:54.458541Z",
     "start_time": "2022-12-12T03:44:47.139832Z"
    }
   },
   "outputs": [],
   "source": [
    "all_test_preds = []\n",
    "for batch in test_input_batches:\n",
    "    preds = predict(model, batch)\n",
    "    all_test_preds.extend(preds)\n",
    "    \n",
    "test_preds = np.zeros((len(all_test_preds), 20))\n",
    "for i, x in enumerate(all_test_preds):\n",
    "    test_preds[i,x] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "fa293d26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T03:48:42.155707Z",
     "start_time": "2022-12-12T03:48:42.134527Z"
    }
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(test_preds.astype(int), columns=training_labels.iloc[:,1:].columns,index=test_arguments['Argument ID'])\n",
    "res.to_csv('./results/test_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5417b7",
   "metadata": {},
   "source": [
    "# Smart Model Approach\n",
    "\n",
    "In this approach, instead of trying to predict if a conclusion is a continuation of the premise, I will just use a pretrained bert model and tell it myself, then use the model as previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d2eaffd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T20:56:44.448523Z",
     "start_time": "2022-12-12T20:56:44.438105Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertForNextSentencePrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0c86fdf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T20:50:12.115479Z",
     "start_time": "2022-12-12T20:50:12.103525Z"
    }
   },
   "outputs": [],
   "source": [
    "class NextSequenceBatchTokenizer:\n",
    "    \"\"\"Tokenizes and pads a batch of input sentences.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the tokenizer\n",
    "\n",
    "        Args:\n",
    "            pad_symbol (Optional[str], optional): The symbol for a pad. Defaults to \"<P>\".\n",
    "        \"\"\"\n",
    "        self.hf_tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-small\")\n",
    "    \n",
    "    def get_sep_token(self,):\n",
    "        return self.hf_tokenizer.sep_token\n",
    "    \n",
    "    def __call__(self, prem_batch: List[str], hyp_batch: List[str], labels) -> List[List[str]]:\n",
    "        \"\"\"Uses the huggingface tokenizer to tokenize and pad a batch.\n",
    "\n",
    "        We return a dictionary of tensors per the huggingface model specification.\n",
    "\n",
    "        Args:\n",
    "            batch (List[str]): A List of sentence strings\n",
    "\n",
    "        Returns:\n",
    "            Dict: The dictionary of token specifications provided by HuggingFace\n",
    "        \"\"\"\n",
    "        # The HF tokenizer will PAD for us, and additionally combine \n",
    "        # The two sentences deimited by the [SEP] token.\n",
    "        enc = self.hf_tokenizer(\n",
    "            prem_batch,\n",
    "            hyp_batch,\n",
    "            padding=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b31176a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T20:58:20.292428Z",
     "start_time": "2022-12-12T20:58:18.547933Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BatchTokenizer()\n",
    "\n",
    "train_input_batches = [b for b in chunk_multi(train_premises, train_conclusions, batch_size)]\n",
    "train_input_batches = [tokenizer(*batch) for batch in train_input_batches]\n",
    "\n",
    "val_input_batches = [b for b in chunk_multi(val_premises, val_conclusions, batch_size)]\n",
    "val_input_batches = [tokenizer(*batch) for batch in val_input_batches]\n",
    "\n",
    "test_input_batches = [b for b in chunk_multi(test_premises, test_conclusions, batch_size)]\n",
    "test_input_batches = [tokenizer(*batch) for batch in test_input_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4745bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments['label'] = (training_arguments['Stance'] == 'in favor of').astype(int)\n",
    "validation_arguments['label'] = (validation_arguments['Stance'] == 'in favor of').astype(int)\n",
    "test_arguments['label'] = (test_arguments['Stance'] == 'in favor of').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "08dddfea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T00:06:22.299844Z",
     "start_time": "2022-12-12T00:06:22.284608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "class SmartClassifier(torch.nn.Module):\n",
    "    def __init__(self, output_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Initialize BERT, which we use instead of a single embedding layer.\n",
    "        self.bert = BertForNextSentencePrediction.from_pretrained(\"prajjwal1/bert-small\")\n",
    "        # Uncommenting out the below 2 lines means only our classification layer will be updated.\n",
    "        # for param in self.bert.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        self.bert_hidden_dimension = self.bert.config.hidden_size\n",
    "        # TODO: Add an extra hidden layer in the classifier, projecting\n",
    "        #      from the BERT hidden dimension to hidden size.\n",
    "        self.hidden_layer = torch.nn.LSTM(self.bert_hidden_dimension, \n",
    "                                         self.hidden_size)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.classifier = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=2)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def encode_text(\n",
    "        self,\n",
    "        symbols: Dict\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Encode the (batch of) sequence(s) of token symbols with an LSTM.\n",
    "            Then, get the last (non-padded) hidden state for each symbol and return that.\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The final hiddens tate of the LSTM, which represents an encoding of\n",
    "                the entire sentence\n",
    "        \"\"\"\n",
    "        # First we get the contextualized embedding for each input symbol\n",
    "        # We no longer need an LSTM, since BERT encodes context and \n",
    "        # gives us a single vector describing the sequence in the form of the [CLS] token.\n",
    "        encoded_sequence = self.bert(**symbols)\n",
    "        # print(encoded_sequence['prediction_logits'].shape)\n",
    "        # # We want to return a tensor of the form batch_size x 1 x bert_hidden_dimension\n",
    "        # curr_batch = encoded_sequence['pooler_output'].shape[0]\n",
    "        # ret_val = encoded_sequence['hidden_states'][:].reshape((curr_batch,\n",
    "        #                                                               1, \n",
    "        #                                                               self.bert_hidden_dimension))\n",
    "        \n",
    "        return encoded_sequence['hidden_states']\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        symbols: Dict,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: _description_\n",
    "        \"\"\"\n",
    "        encoded_sents = self.encode_text(symbols)\n",
    "        print(len(encoded_sents))\n",
    "        print(encoded_sents[0].shape)\n",
    "        output = self.hidden_layer(encoded_sents)\n",
    "        output = self.relu(output[0])\n",
    "        output = self.classifier(output)\n",
    "        return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "7d5b9dc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T03:24:04.432393Z",
     "start_time": "2022-12-12T03:24:04.422988Z"
    },
    "code_folding": [
     3,
     16,
     29,
     39,
     41
    ]
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def precision(predicted_labels, true_labels, which_label=1):\n",
    "#     \"\"\"\n",
    "#     Precision is True Positives / All Positives Predictions\n",
    "#     \"\"\"\n",
    "#     pred_which = np.array(predicted_labels) == which_label\n",
    "#     true_which = np.array(true_labels) == which_label\n",
    "#     denominator = np.sum(pred_which)\n",
    "#     if denominator:\n",
    "#         return np.sum(np.logical_and(pred_which, true_which))/denominator\n",
    "#     else:\n",
    "#         return 0.\n",
    "\n",
    "\n",
    "# def recall(predicted_labels, true_labels, which_label=1):\n",
    "#     \"\"\"\n",
    "#     Recall is True Positives / All Positive Labels\n",
    "#     \"\"\"\n",
    "#     pred_which = np.array(predicted_labels) == which_label\n",
    "#     true_which = np.array(true_labels) == which_label\n",
    "#     denominator = np.sum(true_which)\n",
    "#     if denominator:\n",
    "#         return np.sum(np.logical_and(pred_which, true_which))/denominator\n",
    "#     else:\n",
    "#         return 0.\n",
    "\n",
    "\n",
    "# def f1_score(\n",
    "#     predicted_labels: List[int],\n",
    "#     true_labels: List[int],\n",
    "#     which_label: int\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     F1 score is the harmonic mean of precision and recall\n",
    "#     \"\"\"\n",
    "#     P = precision(predicted_labels, true_labels, which_label=which_label)\n",
    "#     R = recall(predicted_labels, true_labels, which_label=which_label)\n",
    "#     if P and R:\n",
    "#         return 2*P*R/(P+R)\n",
    "#     else:\n",
    "#         return 0.\n",
    "\n",
    "\n",
    "# def macro_f1_score(\n",
    "#     predicted_labels: List[int],\n",
    "#     true_labels: List[int],\n",
    "#     possible_labels: List[int]\n",
    "# ):\n",
    "#     scores = [f1_score(predicted_labels, true_labels, l) for l in possible_labels]\n",
    "#     # Macro, so we take the uniform avg.\n",
    "#     return sum(scores) / len(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
